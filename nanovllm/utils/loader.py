import os
from glob import glob
import torch
from torch import nn
from safetensors import safe_open


def default_weight_loader(param: nn.Parameter, loaded_weight: torch.Tensor):
    param.data.copy_(loaded_weight)


def _load_weight(model, packed_modules_mapping, weight_name, weight_tensor):
    for k in packed_modules_mapping:
        if k in weight_name:
            v, shard_id = packed_modules_mapping[k]
            param_name = weight_name.replace(k, v)
            param = model.get_parameter(param_name)
            weight_loader = getattr(param, "weight_loader")
            weight_loader(param, weight_tensor, shard_id)
            return
    param = model.get_parameter(weight_name)
    weight_loader = getattr(param, "weight_loader", default_weight_loader)
    weight_loader(param, weight_tensor)


def load_model(model: nn.Module, path: str):
    packed_modules_mapping = getattr(model, "packed_modules_mapping", {})
    safetensor_files = glob(os.path.join(path, "*.safetensors"))
    if safetensor_files:
        for file in safetensor_files:
            with safe_open(file, "pt", "cpu") as f:
                for weight_name in f.keys():
                    _load_weight(model, packed_modules_mapping, weight_name, f.get_tensor(weight_name))
    else:
        bin_files = glob(os.path.join(path, "pytorch_model*.bin"))
        for file in bin_files:
            state_dict = torch.load(file, map_location="cpu", weights_only=True)
            for weight_name, weight_tensor in state_dict.items():
                _load_weight(model, packed_modules_mapping, weight_name, weight_tensor)
            del state_dict
